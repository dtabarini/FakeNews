{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 460J Final Project: Fake News Classifier\n",
    "## By: Andy Wu, Dylan Tabarini, Alex Raterink, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exports done\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import statistics\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from statistics import mean\n",
    "from numpy import var, std\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "print('exports done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions here\n",
    "def alert_when_done():\n",
    "  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "\n",
    "def convert_series_to_integer_labels(y_train):\n",
    "    labels = y_train.to_numpy(dtype='str')\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 'fake':\n",
    "            labels[i] = 1\n",
    "        elif labels[i] == 'real':\n",
    "            labels[i] = 0\n",
    "        else:\n",
    "            raise NameError(\"y_train data contains labels that are neither 'fake' nor 'real'!\")\n",
    "    return labels.astype(np.int8)\n",
    "\n",
    "def convert_predictions_to_integer_labels(predictions):\n",
    "    # Passed in predictions should be numpy arrays of np.str_ type\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 'fake':\n",
    "            predictions[i] = 1\n",
    "        elif predictions[i] == 'real':\n",
    "            predictions[i] = 0\n",
    "        else:\n",
    "            raise NameError(\"y_train data contains labels that are neither 'fake' nor 'real'!\")\n",
    "    return predictions.astype(np.int8)\n",
    "\n",
    "def convert_to_tfidf_train_and_test_sets(x_train, x_test):\n",
    "    \"\"\" Returns a tuple containing the converted tfidf vectors: (tfidf_train, tfidf_test)\"\"\"\n",
    "    # Initialize a TfidfVectorizer to filter out English stop words of the most common words and vectorize article text\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(x_train['text'])\n",
    "    tfidf_test = tfidf_vectorizer.transform(x_test['text'])\n",
    "    \n",
    "    # Convert back to a scipy.sparse.csr_matrix\n",
    "    tfidf_train_sparse = scipy.sparse.csr_matrix(tfidf_train_df.values)\n",
    "    tfidf_test_sparse = scipy.sparse.csr_matrix(tfidf_test_df.values)\n",
    "    return (tfidf_train_sparse, tfidf_test_sparse)\n",
    "\n",
    "def convert_to_tfidf_train_and_test_sets_with_sentiment_features(x_train, x_test):\n",
    "    \"\"\" Returns a tuple containing the converted tfidf vectors: (tfidf_train, tfidf_test)\"\"\"\n",
    "    # Initialize a TfidfVectorizer to filter out English stop words of the most common words and vectorize article text\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(x_train['text'])\n",
    "    tfidf_test = tfidf_vectorizer.transform(x_test['text'])\n",
    "    \n",
    "    # Convert the TF IDF sparse matrices into dataframes beforing adding Sentiment feature columns\n",
    "    tfidf_train_df = pd.DataFrame.sparse.from_spmatrix(tfidf_train)\n",
    "    tfidf_test_df = pd.DataFrame.sparse.from_spmatrix(tfidf_test)\n",
    "    \n",
    "    # Add 'tfidf_' suffix to each of the converted tfidf vectors in the train/test sets\n",
    "    tfidf_train_df.columns = ['tfidf_' + str(col) for col in tfidf_train_df.columns]\n",
    "    tfidf_train_df\n",
    "    tfidf_test_df.columns = ['tfidf_' + str(col) for col in tfidf_test_df.columns]\n",
    "    tfidf_test_df\n",
    "    \n",
    "    # Add the 4 sentiment feature columns to both of the 2 converted dataframes\n",
    "    tfidf_train_df['positive'] = x_train['positive'].tolist()\n",
    "    tfidf_train_df['negative'] = x_train['negative'].tolist()\n",
    "    tfidf_train_df['neutral'] = x_train['neutral'].tolist()\n",
    "    tfidf_train_df['mixed'] = x_train['mixed'].tolist()\n",
    "\n",
    "    tfidf_test_df['positive'] = x_test['positive'].tolist()\n",
    "    tfidf_test_df['negative'] = x_test['negative'].tolist()\n",
    "    tfidf_test_df['neutral'] = x_test['neutral'].tolist()\n",
    "    tfidf_test_df['mixed'] = x_test['mixed'].tolist()\n",
    "\n",
    "    # Convert back to a scipy.sparse.csr_matrix\n",
    "    tfidf_train_sparse = scipy.sparse.csr_matrix(tfidf_train_df.values)\n",
    "    tfidf_test_sparse = scipy.sparse.csr_matrix(tfidf_test_df.values)\n",
    "    return (tfidf_train_sparse, tfidf_test_sparse)\n",
    "\n",
    "def get_cv_score(model, x_df, labels, iterations=5, get_details=False, train_split_size=0.80):\n",
    "    \"\"\" \n",
    "        Pass in an untrained model, x_df, and labels to return the average accuracy score across iterations (5 by default).\n",
    "        Note if get_details is set to True, this method returns a tuple in the format:\n",
    "        (mean, std, scores_array)\n",
    "    \"\"\"\n",
    "    auc_scores=[]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        x_train1, x_test1, y_train1, y_test1 = train_test_split(x_df, labels, train_size=train_split_size, test_size=1-train_split_size, random_state=i)\n",
    "        tfidf_train_with_sentiment, tfidf_test_with_sentiment= convert_to_tfidf_train_and_test_sets_with_sentiment_features(x_train1, x_test1)\n",
    "        model.fit(tfidf_train_with_sentiment, y_train1)\n",
    "        true_binary_labels = convert_series_to_integer_labels(y_test1)\n",
    "        predicted_binary_labels = convert_predictions_to_integer_labels(model.predict(tfidf_test_with_sentiment))\n",
    "        auc_scores.append(roc_auc_score(true_binary_labels, predicted_binary_labels))\n",
    "        \n",
    "    if get_details:\n",
    "        return (statistics.mean(auc_scores), np.std(auc_scores), auc_scores)\n",
    "    else:\n",
    "        return statistics.mean(auc_scores)\n",
    "    \n",
    "def get_confusion_matrix(model, x_df, labels):\n",
    "    \"\"\" Given an untrained model and the true labels\"\"\"\n",
    "    x_train1, x_test1, y_train1, y_test1 = train_test_split(x_df, labels, train_size=0.8, test_size=0.2, random_state=SEED)\n",
    "    tfidf_train_with_sentiment, tfidf_test_with_sentiment= convert_to_tfidf_train_and_test_sets_with_sentiment_features(x_train1, x_test1)\n",
    "    model.fit(tfidf_train_with_sentiment, y_train1)\n",
    "    # Visualize the confusion matrix to gain insight into false postives and negatives\n",
    "    predictions = model.predict(tfidf_test_with_sentiment)\n",
    "    return confusion_matrix(y_test1, predictions, labels=['fake','real'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>covid started because we eat animals</td>\n",
       "      <td>vegan instagram users are pinning the coronavi...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>0.899144</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>says michelle obama has people on her staff na...</td>\n",
       "      <td>glenn beck rekindled a falsehood about the siz...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.332251</td>\n",
       "      <td>0.498293</td>\n",
       "      <td>0.159030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>says president donald trump has signed more la...</td>\n",
       "      <td>vice president mike pence says that when it co...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.204091</td>\n",
       "      <td>0.781942</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>us representatives promise implement of un gu...</td>\n",
       "      <td>a conservative website falsely claimed that u ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.565760</td>\n",
       "      <td>0.079329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the federal government borrows billion every ...</td>\n",
       "      <td>hundreds of rhode islanders got phone calls la...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>0.313422</td>\n",
       "      <td>0.630314</td>\n",
       "      <td>0.038955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17482</th>\n",
       "      <td>17482</td>\n",
       "      <td>historically senate ratification of arms cont...</td>\n",
       "      <td>as the house and senate move into a brief lame...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.045163</td>\n",
       "      <td>0.934267</td>\n",
       "      <td>0.014399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>17483</td>\n",
       "      <td>since the affordable care act passed percent ...</td>\n",
       "      <td>policymakers and pundits are spending a lot of...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.292535</td>\n",
       "      <td>0.688702</td>\n",
       "      <td>0.012930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17484</th>\n",
       "      <td>17484</td>\n",
       "      <td>medicare spends billion a year on subsidies to...</td>\n",
       "      <td>in the final presidential debate oct moderator...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.557617</td>\n",
       "      <td>0.433883</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>17485</td>\n",
       "      <td>the obama administration is allowing state wai...</td>\n",
       "      <td>former president bill clinton used his elder s...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.967239</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>17486</td>\n",
       "      <td>the obama administration notified poland and t...</td>\n",
       "      <td>former vice president dick cheney made news on...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.902108</td>\n",
       "      <td>0.012968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17487 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          statement  \\\n",
       "0               0              covid started because we eat animals    \n",
       "1               1  says michelle obama has people on her staff na...   \n",
       "2               2  says president donald trump has signed more la...   \n",
       "3               3   us representatives promise implement of un gu...   \n",
       "4               4   the federal government borrows billion every ...   \n",
       "...           ...                                                ...   \n",
       "17482       17482   historically senate ratification of arms cont...   \n",
       "17483       17483   since the affordable care act passed percent ...   \n",
       "17484       17484  medicare spends billion a year on subsidies to...   \n",
       "17485       17485  the obama administration is allowing state wai...   \n",
       "17486       17486  the obama administration notified poland and t...   \n",
       "\n",
       "                                                    text label  positive  \\\n",
       "0      vegan instagram users are pinning the coronavi...  fake  0.010846   \n",
       "1      glenn beck rekindled a falsehood about the siz...  fake  0.010427   \n",
       "2      vice president mike pence says that when it co...  real  0.011365   \n",
       "3      a conservative website falsely claimed that u ...  fake  0.007493   \n",
       "4      hundreds of rhode islanders got phone calls la...  real  0.017309   \n",
       "...                                                  ...   ...       ...   \n",
       "17482  as the house and senate move into a brief lame...  real  0.006171   \n",
       "17483  policymakers and pundits are spending a lot of...  real  0.005834   \n",
       "17484  in the final presidential debate oct moderator...  real  0.006582   \n",
       "17485  former president bill clinton used his elder s...  real  0.008514   \n",
       "17486  former vice president dick cheney made news on...  real  0.008257   \n",
       "\n",
       "       negative   neutral     mixed  \n",
       "0      0.088485  0.899144  0.001525  \n",
       "1      0.332251  0.498293  0.159030  \n",
       "2      0.204091  0.781942  0.002602  \n",
       "3      0.347418  0.565760  0.079329  \n",
       "4      0.313422  0.630314  0.038955  \n",
       "...         ...       ...       ...  \n",
       "17482  0.045163  0.934267  0.014399  \n",
       "17483  0.292535  0.688702  0.012930  \n",
       "17484  0.557617  0.433883  0.001918  \n",
       "17485  0.020729  0.967239  0.003517  \n",
       "17486  0.076667  0.902108  0.012968  \n",
       "\n",
       "[17487 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv data file. Note that you should replace the line below with the absolute UNIX path of the csv files\n",
    "df = pd.read_csv(\"alldata_with_sentiment.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid started because we eat animals</td>\n",
       "      <td>vegan instagram users are pinning the coronavi...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>0.899144</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says michelle obama has people on her staff na...</td>\n",
       "      <td>glenn beck rekindled a falsehood about the siz...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.332251</td>\n",
       "      <td>0.498293</td>\n",
       "      <td>0.159030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says president donald trump has signed more la...</td>\n",
       "      <td>vice president mike pence says that when it co...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.204091</td>\n",
       "      <td>0.781942</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us representatives promise implement of un gu...</td>\n",
       "      <td>a conservative website falsely claimed that u ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.565760</td>\n",
       "      <td>0.079329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal government borrows billion every ...</td>\n",
       "      <td>hundreds of rhode islanders got phone calls la...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>0.313422</td>\n",
       "      <td>0.630314</td>\n",
       "      <td>0.038955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17482</th>\n",
       "      <td>historically senate ratification of arms cont...</td>\n",
       "      <td>as the house and senate move into a brief lame...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.045163</td>\n",
       "      <td>0.934267</td>\n",
       "      <td>0.014399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>since the affordable care act passed percent ...</td>\n",
       "      <td>policymakers and pundits are spending a lot of...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.292535</td>\n",
       "      <td>0.688702</td>\n",
       "      <td>0.012930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17484</th>\n",
       "      <td>medicare spends billion a year on subsidies to...</td>\n",
       "      <td>in the final presidential debate oct moderator...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.557617</td>\n",
       "      <td>0.433883</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>the obama administration is allowing state wai...</td>\n",
       "      <td>former president bill clinton used his elder s...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.967239</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>the obama administration notified poland and t...</td>\n",
       "      <td>former vice president dick cheney made news on...</td>\n",
       "      <td>real</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.902108</td>\n",
       "      <td>0.012968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17487 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  \\\n",
       "0                  covid started because we eat animals    \n",
       "1      says michelle obama has people on her staff na...   \n",
       "2      says president donald trump has signed more la...   \n",
       "3       us representatives promise implement of un gu...   \n",
       "4       the federal government borrows billion every ...   \n",
       "...                                                  ...   \n",
       "17482   historically senate ratification of arms cont...   \n",
       "17483   since the affordable care act passed percent ...   \n",
       "17484  medicare spends billion a year on subsidies to...   \n",
       "17485  the obama administration is allowing state wai...   \n",
       "17486  the obama administration notified poland and t...   \n",
       "\n",
       "                                                    text label  positive  \\\n",
       "0      vegan instagram users are pinning the coronavi...  fake  0.010846   \n",
       "1      glenn beck rekindled a falsehood about the siz...  fake  0.010427   \n",
       "2      vice president mike pence says that when it co...  real  0.011365   \n",
       "3      a conservative website falsely claimed that u ...  fake  0.007493   \n",
       "4      hundreds of rhode islanders got phone calls la...  real  0.017309   \n",
       "...                                                  ...   ...       ...   \n",
       "17482  as the house and senate move into a brief lame...  real  0.006171   \n",
       "17483  policymakers and pundits are spending a lot of...  real  0.005834   \n",
       "17484  in the final presidential debate oct moderator...  real  0.006582   \n",
       "17485  former president bill clinton used his elder s...  real  0.008514   \n",
       "17486  former vice president dick cheney made news on...  real  0.008257   \n",
       "\n",
       "       negative   neutral     mixed  \n",
       "0      0.088485  0.899144  0.001525  \n",
       "1      0.332251  0.498293  0.159030  \n",
       "2      0.204091  0.781942  0.002602  \n",
       "3      0.347418  0.565760  0.079329  \n",
       "4      0.313422  0.630314  0.038955  \n",
       "...         ...       ...       ...  \n",
       "17482  0.045163  0.934267  0.014399  \n",
       "17483  0.292535  0.688702  0.012930  \n",
       "17484  0.557617  0.433883  0.001918  \n",
       "17485  0.020729  0.967239  0.003517  \n",
       "17486  0.076667  0.902108  0.012968  \n",
       "\n",
       "[17487 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the unamed first column... this is duplicate of the index\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the our overall dataframe has a 17487 datapoints and now 7 features:\n",
    "## statement: title of the article\n",
    "## text: content of the article\n",
    "## label: 'fake' or 'real'\n",
    "## positive, negative, neutral, and mixed scores (4 MORE FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        fake\n",
       "1        fake\n",
       "2        real\n",
       "3        fake\n",
       "4        real\n",
       "         ... \n",
       "17482    real\n",
       "17483    real\n",
       "17484    real\n",
       "17485    real\n",
       "17486    real\n",
       "Name: label, Length: 17487, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the target labels from the dataframe\n",
    "labels = df.label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid started because we eat animals</td>\n",
       "      <td>vegan instagram users are pinning the coronavi...</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>0.899144</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>says michelle obama has people on her staff na...</td>\n",
       "      <td>glenn beck rekindled a falsehood about the siz...</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.332251</td>\n",
       "      <td>0.498293</td>\n",
       "      <td>0.159030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says president donald trump has signed more la...</td>\n",
       "      <td>vice president mike pence says that when it co...</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.204091</td>\n",
       "      <td>0.781942</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us representatives promise implement of un gu...</td>\n",
       "      <td>a conservative website falsely claimed that u ...</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.565760</td>\n",
       "      <td>0.079329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the federal government borrows billion every ...</td>\n",
       "      <td>hundreds of rhode islanders got phone calls la...</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>0.313422</td>\n",
       "      <td>0.630314</td>\n",
       "      <td>0.038955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17482</th>\n",
       "      <td>historically senate ratification of arms cont...</td>\n",
       "      <td>as the house and senate move into a brief lame...</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.045163</td>\n",
       "      <td>0.934267</td>\n",
       "      <td>0.014399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>since the affordable care act passed percent ...</td>\n",
       "      <td>policymakers and pundits are spending a lot of...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.292535</td>\n",
       "      <td>0.688702</td>\n",
       "      <td>0.012930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17484</th>\n",
       "      <td>medicare spends billion a year on subsidies to...</td>\n",
       "      <td>in the final presidential debate oct moderator...</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.557617</td>\n",
       "      <td>0.433883</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17485</th>\n",
       "      <td>the obama administration is allowing state wai...</td>\n",
       "      <td>former president bill clinton used his elder s...</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.967239</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>the obama administration notified poland and t...</td>\n",
       "      <td>former vice president dick cheney made news on...</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.902108</td>\n",
       "      <td>0.012968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17487 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement  \\\n",
       "0                  covid started because we eat animals    \n",
       "1      says michelle obama has people on her staff na...   \n",
       "2      says president donald trump has signed more la...   \n",
       "3       us representatives promise implement of un gu...   \n",
       "4       the federal government borrows billion every ...   \n",
       "...                                                  ...   \n",
       "17482   historically senate ratification of arms cont...   \n",
       "17483   since the affordable care act passed percent ...   \n",
       "17484  medicare spends billion a year on subsidies to...   \n",
       "17485  the obama administration is allowing state wai...   \n",
       "17486  the obama administration notified poland and t...   \n",
       "\n",
       "                                                    text  positive  negative  \\\n",
       "0      vegan instagram users are pinning the coronavi...  0.010846  0.088485   \n",
       "1      glenn beck rekindled a falsehood about the siz...  0.010427  0.332251   \n",
       "2      vice president mike pence says that when it co...  0.011365  0.204091   \n",
       "3      a conservative website falsely claimed that u ...  0.007493  0.347418   \n",
       "4      hundreds of rhode islanders got phone calls la...  0.017309  0.313422   \n",
       "...                                                  ...       ...       ...   \n",
       "17482  as the house and senate move into a brief lame...  0.006171  0.045163   \n",
       "17483  policymakers and pundits are spending a lot of...  0.005834  0.292535   \n",
       "17484  in the final presidential debate oct moderator...  0.006582  0.557617   \n",
       "17485  former president bill clinton used his elder s...  0.008514  0.020729   \n",
       "17486  former vice president dick cheney made news on...  0.008257  0.076667   \n",
       "\n",
       "        neutral     mixed  \n",
       "0      0.899144  0.001525  \n",
       "1      0.498293  0.159030  \n",
       "2      0.781942  0.002602  \n",
       "3      0.565760  0.079329  \n",
       "4      0.630314  0.038955  \n",
       "...         ...       ...  \n",
       "17482  0.934267  0.014399  \n",
       "17483  0.688702  0.012930  \n",
       "17484  0.433883  0.001918  \n",
       "17485  0.967239  0.003517  \n",
       "17486  0.902108  0.012968  \n",
       "\n",
       "[17487 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = df.drop('label', axis=1)\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked\n"
     ]
    }
   ],
   "source": [
    "# Global train and test sets to use (with the added 4 columns)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, labels, train_size=0.8, test_size=0.2, random_state=SEED)\n",
    "tfidf_train_sparse, tfidf_test_sparse = convert_to_tfidf_train_and_test_sets_with_sentiment_features(x_train, x_test)\n",
    "type(tfidf_train_sparse)\n",
    "print(\"worked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (Adding 4 sentiment columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TF IDF sparse matrices into dataframes if we want to add Sentiment feature columns\n",
    "# tfidf_train_df = pd.DataFrame.sparse.from_spmatrix(tfidf_train)\n",
    "# tfidf_test_df = pd.DataFrame.sparse.from_spmatrix(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'tfidf_' suffix to each of the converted tfidf vectors in the training set\n",
    "# tfidf_train_df.columns = ['tfidf_' + str(col) for col in tfidf_train_df.columns]\n",
    "# tfidf_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'tfidf_' suffix to each of the converted tfidf vectors in the test set\n",
    "# tfidf_test_df.columns = ['tfidf_' + str(col) for col in tfidf_test_df.columns]\n",
    "# tfidf_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sentiment feature column to the 2 converted dataframes\n",
    "# tfidf_train_df['positive'] = x_train['positive'].tolist()\n",
    "# tfidf_train_df['negative'] = x_train['negative'].tolist()\n",
    "# tfidf_train_df['neutral'] = x_train['neutral'].tolist()\n",
    "# tfidf_train_df['mixed'] = x_train['mixed'].tolist()\n",
    "\n",
    "# tfidf_test_df['positive'] = x_test['positive'].tolist()\n",
    "# tfidf_test_df['negative'] = x_test['negative'].tolist()\n",
    "# tfidf_test_df['neutral'] = x_test['neutral'].tolist()\n",
    "# tfidf_test_df['mixed'] = x_test['mixed'].tolist()\n",
    "\n",
    "# tfidf_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training\n",
    "## PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score across 5 iterations: 0.6644367416932025\n",
      "Standard Deviation across 5 iterations: 0.004906826893578784\n"
     ]
    }
   ],
   "source": [
    "# Use a PassiveAggressiveClassifier and get the average AUC score across 5 iterations of a 80-20 split\n",
    "pac_clf = PassiveAggressiveClassifier(class_weight='balanced', C=2, max_iter=1e4)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(pac_clf, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6726355486280376, 0.6615907192514724, 0.6670737389342555, 0.6586822469793522, 0.6622014546728949]\n"
     ]
    }
   ],
   "source": [
    "print(scoresArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1115,  569],\n",
       "       [ 568, 1246]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the PassiveAgressiveClassifier\n",
    "conf_matrix = get_confusion_matrix(pac_clf, x_df, labels)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true positives (FAKE article correctly classified): 1115\n",
      "Number of true negatives (REAL article correctly classified): 1246\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 568\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 569\n"
     ]
    }
   ],
   "source": [
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score across 5 iterations: 0.7047333132766321\n",
      "Standard Deviation across 5 iterations: 0.005755272949536468\n",
      "[0.7048819604991997, 0.6937075099589546, 0.7066117364329679, 0.7091681506227709, 0.7092972088692677]\n"
     ]
    }
   ],
   "source": [
    "# Use a SGDClassifier and fit it on the transformed TF-IDF vectors\n",
    "sgd_clf = SGDClassifier(penalty='l1', alpha=0.0001, max_iter=1e4, n_jobs=-1)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(sgd_clf, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')\n",
    "print(scoresArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1017  667]\n",
      " [ 319 1495]]\n",
      "Number of true positives (FAKE article correctly classified): 1017\n",
      "Number of true negatives (REAL article correctly classified): 1495\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 319\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 667\n"
     ]
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the SGDClassifier\n",
    "conf_matrix = get_confusion_matrix(sgd_clf, x_df, labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score across 5 iterations: 0.7138757318577511\n",
      "Standard Deviation across 5 iterations: 0.004123961140671685\n",
      "[0.7142530703084954, 0.7083498294268513, 0.710424483189877, 0.7198290875019009, 0.7165221888616308]\n"
     ]
    }
   ],
   "source": [
    "# Use a LogisticRegressor and fit it on the transformed TF-IDF vectors\n",
    "logistic_classifier = LogisticRegression(penalty='elasticnet', l1_ratio=1, C=1, solver='saga', max_iter=1e4, n_jobs=-1)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(logistic_classifier, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')\n",
    "print(scoresArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1125  559]\n",
      " [ 406 1408]]\n",
      "Number of true positives (FAKE article correctly classified): 1125\n",
      "Number of true negatives (REAL article correctly classified): 1408\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 406\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 559\n"
     ]
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the SGDClassifier\n",
    "conf_matrix = get_confusion_matrix(logistic_classifier, x_df, labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score across 5 iterations: 0.7119332778245612\n",
      "Standard Deviation across 5 iterations: 0.0060951437609422865\n",
      "[0.7067515403847563, 0.7062777784134654, 0.7081365408666225, 0.7208975358970208, 0.717602993560941]\n"
     ]
    }
   ],
   "source": [
    "# Use a XGBClassifier and fit it on the transformed TF-IDF vectors\n",
    "xgb_clf = XGBClassifier(eta=0.01, n_estimators=350, max_depth = 9, n_jobs=-1, verbosity=1)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(xgb_clf, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')\n",
    "print(scoresArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1060  624]\n",
      " [ 359 1455]]\n",
      "Number of true positives (FAKE article correctly classified): 1060\n",
      "Number of true negatives (REAL article correctly classified): 1455\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 359\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 624\n"
     ]
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the XGBClassifier\n",
    "conf_matrix = get_confusion_matrix(xgb_clf, x_df, labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.8min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 12.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 11.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 12.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score across 5 iterations: 0.6937681240564266\n",
      "Standard Deviation across 5 iterations: 0.0020516539293107946\n",
      "[0.6919626044794074, 0.691054186193628, 0.6938487947227739, 0.6954568867827342, 0.6965181481035898]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a RandomForestClassifier and fit it on the transformed TF-IDF vectors\n",
    "random_forest_clf = RandomForestClassifier(class_weight='balanced', \n",
    "                               criterion = 'gini',\n",
    "                               n_estimators= 50, \n",
    "                               min_samples_split=2, \n",
    "                               min_samples_leaf=1,\n",
    "                               min_weight_fraction_leaf=0.0,\n",
    "                               max_features=None,\n",
    "                               max_depth=None, \n",
    "                               bootstrap=True,\n",
    "                               random_state=SEED,\n",
    "                               n_jobs=-1, \n",
    "                               verbose=1)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(random_forest_clf, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')\n",
    "print(scoresArray)\n",
    "alert_when_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 12.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1079  605]\n",
      " [ 459 1355]]\n",
      "Number of true positives (FAKE article correctly classified): 1079\n",
      "Number of true negatives (REAL article correctly classified): 1355\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 459\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 605\n"
     ]
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the RandomForestClassifier\n",
    "conf_matrix = get_confusion_matrix(random_forest_clf, x_df, labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]AUC score across 5 iterations: 0.7141340728798704\n",
      "Standard Deviation across 5 iterations: 0.004489969355050637\n",
      "[0.715412935570596, 0.7100148587438558, 0.7079491895338287, 0.7173787203147458, 0.7199146602363256]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a LinearSVC and fit it on the transformed TF-IDF vectors\n",
    "svc_clf = LinearSVC(class_weight='balanced', penalty='l1', dual=False, C=0.3, max_iter=1e4, verbose=1)\n",
    "aucScore, stdDev, scoresArray = get_cv_score(svc_clf, x_df, labels, iterations=5, get_details=True)\n",
    "print(f'AUC score across 5 iterations: {aucScore}')\n",
    "print(f'Standard Deviation across 5 iterations: {stdDev}')\n",
    "print(scoresArray)\n",
    "alert_when_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][[1125  559]\n",
      " [ 413 1401]]\n",
      "Number of true positives (FAKE article correctly classified): 1125\n",
      "Number of true negatives (REAL article correctly classified): 1401\n",
      "Number of false positives (REAL article wrongly classified as FAKE): 413\n",
      "Number of false negatives (FAKE article wrongly classified as REAL): 559\n"
     ]
    }
   ],
   "source": [
    "# Visualize the confusion matrix for the LinearSVC\n",
    "conf_matrix = get_confusion_matrix(svc_clf, x_df, labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Interpret results of confusion matrix\n",
    "print(f'Number of true positives (FAKE article correctly classified): {conf_matrix[0][0]}')\n",
    "print(f'Number of true negatives (REAL article correctly classified): {conf_matrix[1][1]}')\n",
    "print(f'Number of false positives (REAL article wrongly classified as FAKE): {conf_matrix[1][0]}')\n",
    "print(f'Number of false negatives (FAKE article wrongly classified as REAL): {conf_matrix[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top 3 performing model types after 5-fold validation that we will choose to tune further are:\n",
    "- 1.) LogisticRegressor: 71.5% --> Best AUC score\n",
    "- 2.) LinearSVC: 71.3% --> Also had the lowest standard deviation of 0.00307\n",
    "- 3.) XGBClassifier tuned with (eta=0.01, n_estimators=350, max_depth = 9): 71.1% --> Could possibly do better with more tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-fold Cross-Validation and GridSearch Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4a27cf51ed54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                   \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                   verbosity=1), param_grid, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Run GridSearchCV to find best params for XGBClassifier\n",
    "# Find best n_estimators and max_depth hyperparms using 2D GridSearchCV\n",
    "n_estimators = [x for x in range(100, 1000, 5)]\n",
    "max_depth = [x for x in range(6, 12, 1)]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_depth': max_depth}\n",
    "gridsearch = GridSearchCV(XGBClassifier(\n",
    "                                  eta=0.01, \n",
    "                                  n_estimators=350, \n",
    "                                  max_depth=10, \n",
    "                                  n_jobs=-1, \n",
    "                                  verbosity=1), param_grid, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)\n",
    "gridsearch.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GridSearchCV to find best params for LogisticRegression\n",
    "# Find best n_estimators and max_depth hyperparms using 2D GridSearchCV\n",
    "l1_ratios = [x for x in range(0, 1, 0.1]\n",
    "C_list = [x for x in range(0, 10, 0.1)]\n",
    "param_grid = {'l1_ratio': l1_ratios,\n",
    "              'C': C_list }\n",
    "gridsearch2 = GridSearchCV(LogisticRegression(\n",
    "                                            penalty='elasticnet', \n",
    "                                            l1_ratio=1, \n",
    "                                            C=1, \n",
    "                                            solver='saga', \n",
    "                                            max_iter=1e4, \n",
    "                                            n_jobs=-1), param_grid, scoring='roc_auc', n_jobs=-1, cv=5, verbose=1)\n",
    "gridsearch2.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
